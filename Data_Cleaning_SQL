Overview
The dataset contained information on layoffs across industries, companies, and locations. Raw data often includes inconsistencies, duplicates, or missing values. This phase focused on cleaning the data to ensure its integrity for analysis.

Steps in Data Cleaning
1. Remove Duplicates
Objective: Identify and remove duplicate rows that might skew the analysis.
Approach:
Used a combination of columns (company, location, industry, date, etc.) to detect duplicates.
Rows with identical information were flagged and removed, retaining only the first occurrence.
Outcome: Genuine duplicates were eliminated, leaving unique and accurate entries.

2. Standardize Data
Objective: Ensure consistency in formatting across various columns.
Actions Taken:
Standardized the industry column by consolidating variations (e.g., "CryptoCurrency" → "Crypto").
Fixed inconsistencies in the country column (e.g., "United States." → "United States").
Reformatted the date column to DATE type using the STR_TO_DATE function.
Outcome: Improved data uniformity for analysis.

3. Handle Null Values
Objective: Address missing values in critical columns.
Approach:
Set empty strings in the industry column to NULL for better handling.
Populated missing industry values by referencing rows with the same company name.
Retained null values in numeric fields (e.g., total_laid_off) to ensure accurate calculations during analysis.
Outcome: Missing values were either populated or left as null, ensuring clarity.

4. Remove Unnecessary Rows and Columns
Objective: Eliminate data that does not contribute to the analysis.
Actions Taken:
Removed rows where both total_laid_off and percentage_laid_off were null, as they provided no useful information.
Dropped temporary columns (e.g., row_num) created during the cleaning process.
Outcome: Data was streamlined, reducing noise and improving focus.

Key Highlights
Duplicates removed: Ensured no redundant rows.
Standardized columns: Unified variations in key fields like industry, country, and date.
Addressed missing data: Populated critical null values using logical approaches.
Cleaned dataset size: Reduced the dataset by removing irrelevant rows and columns.
